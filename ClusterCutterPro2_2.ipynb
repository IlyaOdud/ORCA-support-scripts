{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "n_rounds = 6\n",
    "prec = 1e-2\n",
    "\n",
    "class atom2():\n",
    "    def __init__(self, label, spatial_coord, group = None, charge=None):\n",
    "        self.sc = spatial_coord # numpy \n",
    "        self.label = label\n",
    "        self.g = group\n",
    "        self.q = charge\n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, atom2):\n",
    "            return self.label.lower() == other.label.lower() and sum(self.sc == other.sc) == 3\n",
    "        return NotImplemented\n",
    "    def __sub__(self, other):\n",
    "        if isinstance(other, np.ndarray):\n",
    "            return atom2(self.label, self.sc - other, self.g, self.q)\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, np.ndarray):\n",
    "            return atom2(self.label, self.sc + other, self.g, self.q)\n",
    "    def __mul__(self, other):\n",
    "        if isinstance(other, np.ndarray):\n",
    "            return atom2(self.label, np.dot(other, self.sc), self.g, self.q) if np.shape(other)[0] == 3 and np.shape(other)[1] else self\n",
    "        if isinstance(other, (int, float)):\n",
    "            return atom2(self.label, other * self.sc, self.g, self.q)\n",
    "\n",
    "def atom2string(atom_obj):\n",
    "    sp_coord = \"\"\n",
    "    for coord in atom_obj.sc:\n",
    "        sp_coord += str(coord) + \" \"\n",
    "    return atom_obj.label + \" \" + (str(atom_obj.q) + \" \" if atom_obj.label.lower() == \"q\" else \"\") + sp_coord\n",
    "\n",
    "def eq_with_precision(atom_obj_1, atom_obj_2, precision):\n",
    "    return True if sum(np.abs(atom_obj_1.sc - atom_obj_2.sc) < precision) == 3 and atom_obj_1.label.lower() == atom_obj_2.label.lower() else False\n",
    "\n",
    "def writer2file(atom_set, name, group=False):\n",
    "    with open(name + \".xyz\", \"w\") as outtxt:\n",
    "        for atom_obj in atom_set:\n",
    "            outtxt.write(atom2string(atom_obj) + (atom_obj.g if group and atom_obj.g != None else \"\") + \"\\n\")\n",
    "\n",
    "def findID(atomsets, des_atom, precision=0):\n",
    "    indexes = []\n",
    "    for i in range(len(atomsets)):\n",
    "        if ((atomsets[i] == des_atom) if precision == 0 else (eq_with_precision(atomsets[i], des_atom, precision))):\n",
    "            indexes.append(i)\n",
    "        else:\n",
    "            continue\n",
    "    return indexes\n",
    "\n",
    "def removeREP(atomsets):\n",
    "    atomsets_new = atomsets\n",
    "    for atom in atomsets:\n",
    "        index_list = findID(atomsets_new, atom)[::-1]\n",
    "        n = len(index_list)\n",
    "        for i in index_list[:-1]:\n",
    "            atomsets_new.pop(i)\n",
    "    return atomsets_new\n",
    "\n",
    "def reader_out(filename):\n",
    "    lat_flag, lat_i = \"DIRECT LATTICE VECTORS CARTESIAN COMPONENTS (ANGSTROM)\", []\n",
    "    prcell_flag, prcell_i = \"CARTESIAN COORDINATES - PRIMITIVE CELL\", []\n",
    "    lat_set = []\n",
    "    prcell_set = []\n",
    "    with open(filename, \"r\") as inputtxt:\n",
    "        for i, row in enumerate(inputtxt):\n",
    "            #\n",
    "            if lat_flag in row:\n",
    "                lat_i, lat_set = [i + 2, i + 4], []\n",
    "            if len(lat_i) > 0: \n",
    "                if min(lat_i) <= i <= max(lat_i):\n",
    "                    row_tmp = row.strip().split()\n",
    "                    lat_set.append(np.array(row_tmp[:3], dtype=float))\n",
    "            #\n",
    "            if prcell_flag in row: # Put PrCell information here!\n",
    "                prcell_i, prcell_set = [i + 4, i + 8], []\n",
    "            if len(prcell_i) > 0: \n",
    "                if min(prcell_i) <= i <= max(prcell_i):\n",
    "                    row_tmp = row.strip().split()\n",
    "                    prcell_set.append(atom2(row_tmp[2], np.array(row_tmp[3:6], dtype = float)))\n",
    "            #\n",
    "    return lat_set, prcell_set\n",
    "\n",
    "def builder_supercell(l_option_a, l_option_b, l_option_c, lat_set, prcell_set):\n",
    "    atoms_set = []\n",
    "    with open(\"super_cell.xyz\", \"w\") as tmptxt:\n",
    "        for n_a in l_option_a:\n",
    "            for n_b in l_option_b:\n",
    "                for n_c in l_option_c:\n",
    "                    for atom_obj in prcell_set:\n",
    "                        atoms_set.append(atom_obj + (lat_set[0]*n_a + lat_set[1]*n_b + lat_set[2]*n_c))\n",
    "                        tmptxt.write(atom2string(atoms_set[-1])  + \"\\n\")\n",
    "    return atoms_set\n",
    "\n",
    "def cutter_cluster(atoms_set, n_atominprcell, n_waves):\n",
    "    waves_couner, disp = 1, 0.1\n",
    "    atom_init = atoms_set[n_atominprcell]\n",
    "    atom_init.g = 0\n",
    "    TMP_atomwave, TMP_newwave, atoms_set_num = [atom_init], [], [atom_init]\n",
    "    l_range = [1.99800, 2.82560] #[2.48754, 3.45796, 3.64001] # Must be changed for new.out!\n",
    "    norm = lambda np_vector : (sum(np_vector**2))**0.5\n",
    "    while waves_couner < n_waves:\n",
    "        for inwaveatom in TMP_atomwave:\n",
    "            for i in findID(atoms_set, inwaveatom):\n",
    "                atoms_set.pop(i)\n",
    "            for i in range(len(atoms_set)):\n",
    "                if min(l_range) - disp <= norm(atoms_set[i].sc - inwaveatom.sc) <= max(l_range) + disp:\n",
    "                    TMP_newwave.append(atoms_set[i])\n",
    "                else:\n",
    "                    continue\n",
    "        TMP_atomwave = removeREP(TMP_newwave)\n",
    "        waves_couner += 1\n",
    "        atoms_set_num += TMP_atomwave\n",
    "        TMP_newwave = []\n",
    "    return removeREP(atoms_set_num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster generator options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Filename = glob(\"*.out\")[-1]\n",
    "\n",
    "latset, prcellset = reader_out(Filename)            \n",
    "\n",
    "l_option_a = [0, -1, +1, -2, 2, -3, 3]\n",
    "l_option_b = [0, -1, +1, -2, 2, -3, 3]\n",
    "l_option_c = [0, -1, +1, -2, 2, -3, 3]\n",
    "\n",
    "atomset = builder_supercell(l_option_a, l_option_b, l_option_c, latset, prcellset)\n",
    "natominprcell = findID(atomset, prcellset[0])[0]\n",
    "\n",
    "nwaves = 5\n",
    "atomwaves = cutter_cluster(atomset, natominprcell, nwaves) # The last argument must be chosen in accordance with the supercell.\n",
    "\n",
    "with open(\"supcell_sup_waves\" + str(nwaves) + \".xyz\", \"w\") as xyztxt:\n",
    "    for atom_obj in atomwaves:\n",
    "        xyztxt.write(atom2string(atom_obj) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".xyz subtraction.\n",
    "To read .xyz files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 1_BaMC\n",
      "1 : 2_BaPse\n",
      "2 : 3_BaPCh\n",
      "3 : supcell_sup_waves5\n",
      "4 : super_cell\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "pathway = \"C:\\\\WD_PNPI\\\\Cluster_workspace\\\\\"\n",
    "\n",
    "xyz_files = glob(pathway + \"*.xyz\")\n",
    "\n",
    "for i in range(len(xyz_files)):\n",
    "    print(str(i) + \" : \" + xyz_files[i].split(\"\\\\\")[-1].split(\".\")[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_xyz2(filename):\n",
    "    atoms_set = []\n",
    "    with open(filename, \"r\") as xyztxt:\n",
    "        for row in xyztxt:\n",
    "            row_tmp = row.strip().split()\n",
    "            if len(row_tmp) > 3:\n",
    "                if row_tmp[0].lower() == \"q\":\n",
    "                    atoms_set.append(atom2(row_tmp[0], np.array(row_tmp[2:5], dtype = float), charge=float(row_tmp[1])))\n",
    "                else:\n",
    "                    atoms_set.append(atom2(row_tmp[0], np.array(row_tmp[1:4], dtype = float)))\n",
    "            else:\n",
    "                continue\n",
    "    return atoms_set\n",
    "\n",
    "def subtrack_xyz(file1, file2): # file1 - reduced >= file2 - subtracted\n",
    "    atoms_set_1, atoms_set_2 = reader_xyz2(file1), reader_xyz2(file2)\n",
    "    for atom_obj in atoms_set_2:\n",
    "        index_list = findID(atoms_set_1, atom_obj, prec)\n",
    "        for i in index_list:\n",
    "            atoms_set_1.pop(i)\n",
    "    writer2file(atoms_set_1, pathway + file1.split(\"\\\\\")[-1].split(\".\")[0] + \"-\" + file2.split(\"\\\\\")[-1].split(\".\")[0] + \".xyz\")\n",
    "    return atoms_set_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subtrack_xyz(xyz_files[7], xyz_files[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def rotmat(direction, angle):\n",
    "    from math import cos, sin, pi\n",
    "    x, y, z = direction[0], direction[1], direction[2] \n",
    "    cost, sint = cos(angle/180 * pi), sin(angle/180 * pi) \n",
    "    return np.array([\n",
    "        [cost + (1 - cost)*x*x, (1 - cost)*x*y - sint*z, (1 - cost)*x*z + sint*y],\n",
    "        [(1 - cost)*y*x + sint*z, cost + (1 - cost)*y*y, (1 - cost)*y*z - sint*x],\n",
    "        [(1 - cost)*z*x - sint*y, (1 - cost)*z*y + sint*x, cost + (1 - cost)*z*z]\n",
    "    ])\n",
    "\n",
    "def findidintrack(track, id):\n",
    "    for trace in track:\n",
    "        if id in trace: return True\n",
    "        else: continue\n",
    "    return False\n",
    "\n",
    "def dividerpro_track(atoms_set, track, ActionMatrix, actionorder):\n",
    "    track_new = []\n",
    "    for trace in track:\n",
    "        for atom_id in trace:\n",
    "            if not findidintrack(track_new, atom_id):\n",
    "                atom_obj = atoms_set[atom_id]\n",
    "                trace_new = [atom_id]\n",
    "                for round in range(actionorder):\n",
    "                    atom_obj = atom_obj * ActionMatrix\n",
    "                    list_of_ids = findID([atoms_set[i] for i in trace], atom_obj, prec)\n",
    "                    if len(list_of_ids) > 0:\n",
    "                        if trace_new[0] != list_of_ids[0]: trace_new.append(list_of_ids[0])\n",
    "                        else:\n",
    "                            track_new += [trace_new]\n",
    "                            break\n",
    "                    else: continue\n",
    "            else: continue\n",
    "    return track_new       \n",
    "\n",
    "def findtraceintrace(trace_big, trace_small):\n",
    "    containslist = [False] * len(trace_small)\n",
    "    for id_b in trace_big:\n",
    "        for i, id_s in enumerate(trace_small):\n",
    "            if id_b == id_s: containslist[i] = True\n",
    "            else: continue\n",
    "    return True if sum(containslist) == len(trace_small) else False\n",
    "\n",
    "def findtraceintrack(track_new, trace):\n",
    "    for trace_new in track_new:\n",
    "        if findtraceintrace(trace_new, trace): return True\n",
    "        else: continue\n",
    "    return False\n",
    "\n",
    "def mergerpro_track(atoms_set, track, ActionMatrix, actionorder):\n",
    "    track_new = []\n",
    "    for trace in track:\n",
    "        if not findtraceintrack(track_new, trace):\n",
    "            trace_new = trace\n",
    "            trace_tmp = trace\n",
    "            for round in range(actionorder):\n",
    "                trace_tmp = [findID(atoms_set, atoms_set[atom_id] * ActionMatrix, prec) for atom_id in trace_tmp]\n",
    "                if not ([] in trace_tmp): trace_tmp = [ids[0] for ids in trace_tmp]\n",
    "                else:\n",
    "                    track_new += [trace_new]\n",
    "                    break\n",
    "                if not findtraceintrace(trace_new, trace_tmp): trace_new += trace_tmp\n",
    "                else:\n",
    "                    track_new += [trace_new]\n",
    "                    break\n",
    "        else: continue\n",
    "    return track_new\n",
    "\n",
    "filename = xyz_files[2]\n",
    "atomsset = reader_xyz2(filename)\n",
    "track0 = [[i for i in range(len(atomsset))]]\n",
    "track1 = dividerpro_track(atomsset, track0, rotmat([0, 0, 1], 360/4), 4)\n",
    "track2 = mergerpro_track(atomsset, track1, np.array([[1, 0, 0], [0, 1, 0], [0, 0, -1]]), 2)\n",
    "\n",
    "def assigngroup(atomsset, track):\n",
    "    for id_group, trace in enumerate(track):\n",
    "        for id_atom in trace:\n",
    "            atomsset[id_atom].g = (\"@g\" if len(trace) > 1 else \"@s\") + str(id_group + 1)\n",
    "    return atomsset\n",
    "\n",
    "writer2file(assigngroup(atomsset, track2), filename.split(\".\")[0] + \"_test_g2\", True)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
